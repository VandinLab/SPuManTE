diff --git a/exper/code/rade_bounds.cpp b/exper/code/rade_bounds.cpp
index 96666d8..8e10c6b 100644
--- a/exper/code/rade_bounds.cpp
+++ b/exper/code/rade_bounds.cpp
@@ -111,6 +111,7 @@ long double get_rademacher_bound_optimize() {
 	for (auto element : all_sampled_transactions) {
 		set<unsigned int> transaction_set;
 		// Filter out items that are not in sample_items
+		// XXX: 20180705 Matteo: how can there be such items?
 		for (unsigned int item : element.first) {
 			if (sample_items_sample_as_set.count(item) > 0) {
 				transaction_set.insert(item);
@@ -118,6 +119,7 @@ long double get_rademacher_bound_optimize() {
 		}
 		// Pass to the next transaction if no items from sample_items are in
 		// this transaction.
+		// XXX: see XXX note earlier.
 		if (transaction_set.size() == 0) {
 			continue;
 		}
@@ -150,7 +152,7 @@ long double get_rademacher_bound_optimize() {
 			}
 			transaction_lengths[item][i]++;
 		}
-	}
+	} // end of for loop through all_sampled_transactions
 	// Now, for each item 'a', and each "length" 'ell' in the map of 'a', we first
 	// compute the number of transactions with length greater than 'ell', then
 	// we "virtually" impose a total order between the transactions of length at
diff --git a/exper/code/sortFIs.cpp b/exper/code/sortFIs.cpp
index 2eaaa36..8043575 100644
--- a/exper/code/sortFIs.cpp
+++ b/exper/code/sortFIs.cpp
@@ -1,6 +1,8 @@
 /**
  * Sort a collection of itemsets in decreasing order according to their
- * frequency
+ * frequency, with the items in each itemset sorted in decreasing order
+ * according to their frequency. The input is assumed to be the output of the
+ * minedb_grahne.sh script.
  *
  * Copyright 2014 Matteo Riondato <matteo@cs.brown.edu>
  *
@@ -15,67 +17,78 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- * 
+ *
  */
 
+#include <algorithm>
 #include <cerrno>
-#include <cstdio>
 #include <cstdlib>
 #include <cstring>
+#include <fstream>
 #include <iostream>
 #include <map>
+#include <sstream>
 #include <vector>
 
-#include "util.h"
-
-using namespace std;
+#include "amira.h"
 
 int main(int argc, char **argv) {
-	if (argc != 2) {
-		cerr << argv[0] << 
-			": sort a collection of itemsets in decreasing order according to their frequency"
-			<< endl; 
-		cerr << "USAGE: " << argv[0] << " itemsets_file" << endl;
-		return 1;
-	}
-
-	FILE *in_FILE = fopen(argv[1], "r");
-	if (in_FILE == NULL) {
-		perror("Error opening input file");
-		return errno;
-	}
+    if (argc != 2) {
+        std::cerr << argv[0] << ": sort a collection of itemsets in decreasing "
+            "order according to their frequency" << std::endl << "USAGE: "
+            << argv[0] << " itemsets_file" << std::endl;
+        return 1;
+    }
+    const std::string input {argv[1]};
+    std::ifstream in(input);
 
-	/* first line is special */
-	char first_line[TRANSACTION_LINE_MAXLEN]; 
-	fgets(first_line, TRANSACTION_LINE_MAXLEN, in_FILE);
-	cout << first_line;
+    // The first line is special: it contains the size of the dataset
+    std::string line;
+    std::getline(in, line);
+    std::cout << line << std::endl;
 
-	map<long int,vector<string> > supp_map;
-	
-	char line[TRANSACTION_LINE_MAXLEN];
-	while (! feof(in_FILE)) {
-		fgets(line, TRANSACTION_LINE_MAXLEN, in_FILE);
-		char *open_par = strchr(line, '(');	
-		if (open_par == NULL) {
-			continue;
-		}
-		string itemset(line, open_par - line);
-		long int support = strtol(open_par + 1, NULL, 10);
-		if (supp_map.count(support) == 0) { 
-			supp_map[support] = vector<string>();
-		}
-		supp_map[support].push_back(itemset);
-	}
-
-	for (auto rit = supp_map.rbegin(); rit != supp_map.rend(); ++rit) {
-		long int support = rit->first;
-		vector<string> itemsets = rit->second;
-		for (string itemset : itemsets) {
-			cout << itemset << "(" << support << ")" << endl;
-		}
-	}
-
-	fclose(in_FILE);
-	return 0;
+    // Map from support to vector of itemsets with that support. We rely on the
+    // order of std::map to sort the itemsets by support.
+    std::map<long int,std::vector<std::vector<item>>> supps;
+    // The following vectors has, in position i, the support for item i.
+    std::vector<supp> itemsupps;
+    // Scan the rest of the file.
+    while (std::getline(in, line)) {
+        const auto open_par_pos {line.find('(')};
+        // XXX The following should never happen, in theory. Should we throw?
+        if (open_par_pos == std::string::npos)
+            continue;
+        // Get the support
+        const auto support {static_cast<supp>(std::strtoul(
+                    line.substr(open_par_pos + 1).c_str(), NULL, 10))};
+        // Parse the itemset
+        std::istringstream ls {line.substr(0, open_par_pos)};
+        const std::vector<unsigned int> itemset {
+            std::istream_iterator<unsigned int>(ls),
+                std::istream_iterator<unsigned int>()};
+        // If this itemset is a single item, save its support.
+        if (itemset.size() == 1) {
+            if (itemsupps.size() <= itemset[0])
+                itemsupps.resize(itemset[0] + 1);
+            itemsupps[itemset[0] + 1] = support;
+        }
+        if (auto it {supps.lower_bound(support)}; it->first != support)
+            supps.emplace_hint(it, support,
+                    std::vector<std::vector<unsigned int>>(1, itemset));
+        else
+            it->second.push_back(itemset);
+    }
+    const SuppComp sc {itemsupps};
+    for (auto rit {supps.rbegin()}; rit != supps.rend(); ++rit) {
+        // XXX: do we need to sort the itemsets according to the order <_H?
+        for (const auto & itemset : rit->second) {
+            // Sort the items in the itemset in reverse order according to their
+            // frequency in the sample.
+            std::sort(itemset.rbegin(), itemset.rend(), sc);
+            for (const auto itm : itemset)
+                std::cout << itm << " ";
+            std::cout << "(" << rit->first << ")" << std::endl;
+        }
+    }
+    return EXIT_SUCCESS;
 }
-
diff --git a/exper/newcode/amira.cpp b/exper/newcode/amira.cpp
index 9fb48db..a3d1cd0 100644
--- a/exper/newcode/amira.cpp
+++ b/exper/newcode/amira.cpp
@@ -44,8 +44,9 @@
 void usage(const char *binary, const int code) {
     std::cerr << binary << ": run AMIRA with a fixed sample size" << std::endl
         << "USAGE: " << binary
-        << " [-c] [-d dataset_size] [-fh] [-jnp] [-s sample] [-v] "
-        "failure_probability minimum_frequency sample_size dataset" << std::endl
+        << " [-c] [-d dataset_size] [-fh] [-i ignore_frequency] [-jnp] "
+        "[-s sample] [-v] failure_probability minimum_frequency sample_size "
+        "dataset" << std::endl
         << "\t-c : print the closed frequent itemsets, rather than the "
         "frequent ones" << std::endl
         << "\t-f : print full information about the run at the end" << std::endl
@@ -68,12 +69,13 @@ int main(int argc, char** argv) {
     bool printclosed {false};
     bool skipsecond {false};
     bool verbose {false};
+    double ignore_freq {0};
     amira::count ds_size {0};
     std::string outf;
     char opt;
     extern char *optarg;
     extern int optind;
-    while ((opt = getopt(argc, argv, "cd:fhjnps:v")) != -1) {
+    while ((opt = getopt(argc, argv, "cd:fhi:jnps:v")) != -1) {
         switch (opt) {
             case 'c':
                 printclosed = true;
@@ -92,6 +94,14 @@ int main(int argc, char** argv) {
             case 'h':
                 usage(argv[0], EXIT_SUCCESS);
                 break;
+            case 'i':
+                ignore_freq = std::strtod(optarg, NULL);
+                if (errno == ERANGE || ignore_freq == 0 || ignore_freq >= 1) {
+                    std::cerr << "Error: ignore_freq must be a real in [0,1)"
+                        << std::endl;
+                    return EXIT_FAILURE;
+                }
+                break;
             case 'j':
                 json = true;
                 break;
@@ -162,6 +172,8 @@ int main(int argc, char** argv) {
     // The sampled transactions.
     std::vector<amira::itemset> sample;
     std::map<amira::item,amira::ItemsetInfo> item_infos;
+    const amira::count ignore_supp {static_cast<amira::count>(std::ceil(size *
+                ignore_freq))};
     // Create the sample and populate the item_infos data structure needed to
     // compute the first omega and the first rho.
     // XXX MR: Strictly speaking, in terms of running time, populating the data
@@ -169,7 +181,8 @@ int main(int argc, char** argv) {
     // omega1 and rho1, but implementation-wise, it is easier to populate the
     // structure in create_sample.
     try {
-        amira::create_sample(dataset, ds_size, size, sample, item_infos);
+        amira::create_sample(dataset, ds_size, size, ignore_freq, sample,
+                item_infos);
     } catch (std::runtime_error &e) {
         std::cerr << "Error: " << e.what() << std::endl;
         return EXIT_FAILURE;
@@ -192,7 +205,7 @@ int main(int argc, char** argv) {
     const auto rho1_start {std::chrono::system_clock::now()};
     amira::EraEps item_er; // stores omega1 and rho1
     try {
-        amira::compute_eraeps(delta, size, item_infos, item_er);
+        amira::compute_eraeps(delta, size, item_infos, ignore_freq, item_er);
     } catch (const std::runtime_error &e) {
         std::cerr << "Error: " << e.what() << std::endl;
         return EXIT_FAILURE;
@@ -206,6 +219,8 @@ int main(int argc, char** argv) {
     double freq1 {theta - item_er.eps};
     if (freq1 <= 0)
         freq1 = 1.0 / size;
+    if (freq1 < ignore_freq)
+        freq1 = ignore_freq;
     if (verbose)
         std::cerr << freq1 << "...";
     const amira::count supp1 {
@@ -232,10 +247,11 @@ int main(int argc, char** argv) {
         goto output;
     if (verbose)
         std::cerr << "Computing omega2 and rho2...";
-    // Add to q the items that are not frequent wrt freq1
+    // Add to q the items that are not frequent wrt freq1, but have frequency
+    // greater than ignore_freq
     {
         for (const auto &ii : item_infos)
-            if (ii.second.sp < supp1)
+            if (ii.second.sp < supp1 && ii.second.sp >= ignore_supp)
                 // We cannot reuse ii.second because its g and h are already
                 // populated, while we want ``vanilla' ones.
                 q.emplace(amira::itemset({ii.first}),
@@ -282,9 +298,7 @@ int main(int argc, char** argv) {
     }
     // Compute omega2 and rho2
     try {
-        const amira::count supp1_minus1 {supp1 - 1};
-        auto data {std::tie(supp1_minus1, std::as_const(q))};
-        amira::compute_eraeps(delta, size, data, itemset_er);
+        amira::compute_eraeps(delta, size, q, freq1, itemset_er);
     } catch (const std::runtime_error &e) {
         std::cerr << "Error: " << e.what() << std::endl;
         return EXIT_FAILURE;
@@ -351,6 +365,7 @@ output:
             << tab << "samplesize: " << size << comma << std::endl
             << tab << "minimum_frequency: " << theta << comma << std::endl
             << tab << "failure_probability: " << delta << comma << std::endl
+            << tab << "ignore_frequency: " << ignore_freq << comma << std::endl
             << tab << "printclosed: " << ((printclosed) ? 1 : 0) << comma
             << std::endl
             << tab << "skipsecond: " << ((skipsecond) ? 1 : 0) << comma
diff --git a/exper/newcode/epsilon.h b/exper/newcode/epsilon.h
index b277517..b847873 100644
--- a/exper/newcode/epsilon.h
+++ b/exper/newcode/epsilon.h
@@ -54,10 +54,14 @@ namespace impl {
 // bound to the empirical Rademacher average (also known as omega1).
 inline double items_objective(const std::vector<double> &x,
         std::vector<double> &, void *data) {
-    const auto &infos {*(static_cast<std::map<item,ItemsetInfo>*>(data))};
+    auto& [ignore_supp, infos] {*(
+            static_cast<std::tuple<count const &,
+            std::map<item,ItemsetInfo> const &>*>( data))};
     const auto lncoshx {MatteoUtils::logcosh(x[0])};
     MatteoUtils::LogSumFromLogs sum {std::numeric_limits<double>::lowest()};
     for (const auto &info : infos) {
+        if (info.second.sp < ignore_supp)
+            continue;
         const auto &h {info.second.h};
         sum += info.second.sp * lncoshx;
         for (const auto &gv : info.second.g) {
@@ -134,11 +138,11 @@ inline double itemset_objective(const std::vector<double> &x,
 } // namespace impl
 
 template<class T> void compute_eraeps(const double d, const count size,
-        T &data, EraEps &res, typename std::enable_if_t<
+        const T &infos, double ignore_or_mine_freq, EraEps &res,
+        typename std::enable_if_t<
         std::is_same<T, std::map<item,ItemsetInfo>>::value ||
-        std::is_same<T, std::tuple<count const &,
-                std::set<amira::ItemsetWithInfo,
-                amira::SuppThenInvByLengthComp> const &>>::value,
+        std::is_same<T,
+            std::set<ItemsetWithInfo, SuppThenInvByLengthComp>>::value,
             bool> = false) {
     // Use the infos to compute the upper bound for the Rademacher average.
     // Most of the following code comes from Wheelwright.
@@ -159,24 +163,40 @@ template<class T> void compute_eraeps(const double d, const count size,
     // Set initialization point. The choice of '2' is somewhat arbitrary.
     std::vector<double> x {2.0};
     double objval {0};
+    // Create auxiliary data and do the minimization
     if constexpr (std::is_same<T, std::map<item,ItemsetInfo>>::value) {
+        // ceil to use < in items_objective
+        const amira::count ignore_supp {static_cast<amira::count>(
+            std::ceil(size * ignore_or_mine_freq))};
+        auto ignoresupp_and_infos {std::tie(ignore_supp, infos)};
         opt_prob.set_min_objective(impl::items_objective,
-                &data);
+                &ignoresupp_and_infos);
+        try {
+            opt_prob.optimize(x, objval);
+        } catch (const std::runtime_error &e) {
+            std::stringstream ss;
+            ss << "Error in the optimization: either a generic NLopt failure or "
+                "the objective function computation threw a std::runtime_error. "
+                "The message was: " << e.what();
+            throw std::runtime_error(ss.str());
+        }
     } else if constexpr (std::is_same<T,
-            std::tuple<count const &,
-                std::set<amira::ItemsetWithInfo,
-                amira::SuppThenInvByLengthComp> const &>>::value) {
+            std::set<ItemsetWithInfo, SuppThenInvByLengthComp>>::value) {
+        const amira::count mine_supp {static_cast<amira::count>(
+            std::ceil(size * ignore_or_mine_freq)) - 1};
+        auto minesupp_and_infos {std::tie(mine_supp,
+                infos)};
         opt_prob.set_min_objective(impl::itemset_objective,
-                &data);
-    }
-    try {
-        opt_prob.optimize(x, objval);
-    } catch (const std::runtime_error &e) {
-        std::stringstream ss;
-        ss << "Error in the optimization: either a generic NLopt failure or "
-            "the objective function computation threw a std::runtime_error. "
-            "The message was: " << e.what();
-        throw std::runtime_error(ss.str());
+                &minesupp_and_infos);
+        try {
+            opt_prob.optimize(x, objval);
+        } catch (const std::runtime_error &e) {
+            std::stringstream ss;
+            ss << "Error in the optimization: either a generic NLopt failure or "
+                "the objective function computation threw a std::runtime_error. "
+                "The message was: " << e.what();
+            throw std::runtime_error(ss.str());
+        }
     }
     // Divide by size because objective() computes the objective value
     // multiplied by the sample size.
diff --git a/exper/newcode/sample.h b/exper/newcode/sample.h
index 7f68a71..f6fcf00 100644
--- a/exper/newcode/sample.h
+++ b/exper/newcode/sample.h
@@ -30,6 +30,7 @@
 #include <stdexcept>
 #include <sstream>
 #include <string>
+#include <unordered_map>
 #include <vector>
 
 #include "wheelwright/matteoutils/Sampler.h"
@@ -45,13 +46,9 @@ namespace amira {
 // from the file dataset, which contains ds_size transactions. The information
 // infos needed for computing the first error bounds are also populated.
 void create_sample(const std::string &dataset, const count ds_size,
-        const count sample_size, std::vector<itemset> &sample,
-        std::map<item,ItemsetInfo> &infos) {
-    // indices (in sample) of the first copy of a sampled transaction, needed
-    // for populating infos later. The members g and h of the ItemsetInfo's in
-    // infos are only updated the for the first copy of a transaction, because
-    // successive copies do not change the number of closed itemsets.
-    std::vector<count> first_idxs;
+        const count sample_size, const count ignore_supp,
+        std::vector<itemset> &sample, std::map<item,ItemsetInfo> &infos) {
+    std::unordered_map<itemset,count,ItemsetHash> transactions;
     {
         std::ifstream ds {dataset};
         if (ds.fail())
@@ -66,7 +63,6 @@ void create_sample(const std::string &dataset, const count ds_size,
             std::iota(tosample_idxs.begin(), tosample_idxs.end(), 0);
         }
         std::sort(tosample_idxs.begin(), tosample_idxs.end());
-        first_idxs.reserve(sample_size); // XXX MR: conservative allocation.
         // index in the dataset of the transaction just read
         std::size_t curr_idx {0};
         auto idxsit {tosample_idxs.begin()};
@@ -88,14 +84,14 @@ void create_sample(const std::string &dataset, const count ds_size,
             // we need a consistent ordering of itemset in transactions and cfis
             // to populate the itemset infos needed to compute omega2 and rho2.
             std::sort(t.begin(), t.end());
-            first_idxs.push_back(sample.size());
             count copies {0};
             // Add the transaction to the sample (possibly multiple times).
             do {
-                sample.push_back(t);
                 ++idxsit;
                 ++copies;
             } while (idxsit != tosample_idxs.end() && curr_idx == *idxsit);
+            if (! transactions.emplace(t, copies).second)
+                transactions[t] += copies;
             for (const auto i : t) {
                 if (const auto infit {infos.lower_bound(i)};
                         infit == infos.end() || infit->first != i)
@@ -106,6 +102,21 @@ void create_sample(const std::string &dataset, const count ds_size,
             ++curr_idx;
         }
     }
+    std::vector<item> ignored_items;
+    for (const auto& p : infos)
+        if (p.second.sp <= ignore_supp)
+            ignored_items.push_back(p.first);
+    std::unordered_map<itemset, item> t2itm;
+    for (const auto &p : transactions) {
+        itemset tc;
+        std::set_difference(p.first.cbegin(), p.first.cend(),
+                ignored_items.cbegin(), ignored_items.cend(),
+                std::back_inserter(tc));
+        if (! tc.empty()) {
+
+        }
+    }
+
     // Populate the infos of the items appearing in the sample.
     for (const auto i : first_idxs) {
         const auto &t {sample[i]};
diff --git a/paper/algo.tex b/paper/algo.tex
index 35049e0..e83a56a 100644
--- a/paper/algo.tex
+++ b/paper/algo.tex
@@ -304,8 +304,8 @@ Let
   \mathcal{P}_A\} - |A|
 \end{equation}
 be the maximum $r$ such that there exists at least one transaction in
-$\mathcal{P}_A$ containing exactly $r$ items that come after $A$ in the
-order $<_\mathcal{H}$. Finally let
+$\mathcal{P}_A$ containing exactly $r$ items whose representatives come after
+$A$ in the order $<_\mathcal{H}$. Finally let
 \begin{equation}\label{eq:har}
   h_{A,r} = |\{ \tau \in \mathcal{P}_A ~:~ |\tau| - |A| \ge r \}| =
   \sum_{j\ge r}^{\chi_A} g_{A,j}
@@ -314,11 +314,12 @@ be the number of transactions in $\mathcal{P}_A$ that contain \emph{at least}
 $r$ items whose representatives come after $A$ in the order $<_\mathcal{H}$.
 
 Now, assume that $\tau$ is the $\ell_{A,\tau}$-th transaction in the ordering
-$<_A$ that contains exactly $k_{A,\tau}$ items whose representatives after $A$
-in the ordering $<_\mathcal{H}$. In other words, if we consider only the
-transactions containing exactly $k_{A,\tau}$ items that come after $A$ in the
-ordering $<_\mathcal{H}$ (i.e., the transactions in $\mathcal{P}_A$ of size
-exactly $|A|+k_{A,\tau}$), then $\tau$ is the $\ell_{A,\tau}$-th of such
+$<_A$ that contains exactly $k_{A,\tau}$ items whose representatives come after
+$A$ in the ordering $<_\mathcal{H}$. In other words, if we consider only the
+transactions containing exactly $k_{A,\tau}$ items whose representatives come
+after $A$ in the ordering $<_\mathcal{H}$ (i.e., the transactions in
+$\mathcal{P}_A$ of size exactly $|A|+k_{A,\tau}$), then $\tau$ is the
+$\ell_{A,\tau}$-th of such
 transactions in the ordering $<_A$. The counting starts from $1$, i.e., if
 $\tau$ is the \emph{first} transaction, then  $\ell_{A,\tau}=1$.
 
@@ -328,12 +329,14 @@ $\tau$ is the \emph{first} transaction, then  $\ell_{A,\tau}=1$.
     |\partit_{A,\tau}|
     \begin{cases}
       = 0 & \text{if } k_{A,\tau}=0 \\
-      \le \min\left\{2^{\min\{k_{A,\tau}, h_{A,k_{A,\tau}} -
-    \ell_{A,\tau}\}}, \displaystyle\sum_{i=0}^{\lceil\lambda
+      \le \min\left\{2^{k_{A,\tau}}
+        %{\min\{k_{A,\tau}, h_{A,k_{A,\tau}} - \ell_{A,\tau}\}}
+        , \displaystyle\sum_{i=0}^{\lceil\lambda
   n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i} \right\} &
   \text{otherwise}
     \end{cases}
-    \enspace.
+    \enspace.\footnote{We follow the convention that $\binom{a}{b}=0$ for any
+    $0<a<b$, and $\binom{a}{0}=1$ for any $a>0$.}
   \]
 \end{lemma}
 
@@ -346,9 +349,9 @@ $\tau$ is the \emph{first} transaction, then  $\ell_{A,\tau}=1$.
 
   The quantity $2^{k_{A,\tau}}$ is the number of subsets $B$ of $\tau$ such that
   $B=A\cup C$ where $C$ is any non-empty subset of $\tau$ containing only items
-  that come after $A$ in the order $<_\mathcal{H}$. Since $\partit_{A,\tau}$
-  contains only itemsets that appear in $\tau$ and are in the form of $B$, then
-  $|\partit_{A,\tau}|\le 2^{k_{A,\tau}}$.
+  whose representative after $A$ in the order $<_\mathcal{H}$. Since
+  $\partit_{A,\tau}$ contains only itemsets that appear in $\tau$ and are in the
+  form of $B$, then $|\partit_{A,\tau}|\le 2^{k_{A,\tau}}$.
 
   Consider now an itemset $B\in\partit_{A,\tau}$. Apart from $\tau$, $B$ may
   only appear in the transactions in a subset of the set
@@ -359,7 +362,7 @@ $\tau$ is the \emph{first} transaction, then  $\ell_{A,\tau}=1$.
   $|\mathcal{J}|=h_{A,k_{A,\tau}} - \ell_{A,\tau}$. From
   \lemmaref{lem:singleci} we know that there is at most one CI for each set
   $D=\{\tau\}\cup\mathcal{L}$ of transactions, for
-  $\mathcal{L}\subseteq\mathcal{C}$ and $D$ is the support set of that CI. For
+  $\mathcal{L}\subseteq\mathcal{J}$ and $D$ is the support set of that CI. For
   each such $D$ for which there is one CI with support set $D$, let $\zeta(D)$
   be that CI. For any $D$ with size $|D|\ge \lceil\lambda n\rceil$, $\zeta(D)$
   has frequency in $\Sam$ at least $\lambda$ so it must hold
@@ -369,8 +372,10 @@ $\tau$ is the \emph{first} transaction, then  $\ell_{A,\tau}=1$.
   $D=\{\tau\}\cup\mathcal{L}$ with $\mathcal{L}\subseteq\mathcal{J}$ and
   $|\mathcal{L}| \le \lceil\lambda n\rceil-2$. There are
   \[
-    \min\left\{2^{h_{A,k_{A,\tau}} - \ell_{A,\tau}}, \sum_{i=0}^{\lceil\lambda
-      n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i}\right\}
+    \sum_{i=0}^{\lceil\lambda n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i}
+    % 20181108 Matteo: The sum is actually sufficient.
+    %\min\left\{2^{h_{A,k_{A,\tau}} - \ell_{A,\tau}}, \sum_{i=0}^{\lceil\lambda
+    %  n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i}\right\}
   \]
   such subsets of $\mathcal{J}$, so there could at most these many CIs in
   $\partit_{A,\tau}$.
@@ -387,8 +392,9 @@ and \equationref{eq:partitioning}.
     |\partit_\mathcal{H}| +
     \sum_{A\in\mathcal{H}} \sum_{\shortstack{\footnotesize$\tau\in
     \mathcal{P}_A$\\\footnotesize s.t.~$k_{A,\tau}>0$}}
-    \min\left\{2^{\min\{k_{A,\tau}, h_{A,k_{A,\tau}} -
-    \ell_{A,\tau}\}}, \sum_{i=0}^{\lceil\lambda
+    \min\left\{2^{k_{A,\tau}}
+        % \min\{k_{A,\tau}, h_{A,k_{A,\tau}} - \ell_{A,\tau}\}}
+        , \sum_{i=0}^{\lceil\lambda
       n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i} \right\}\enspace.
   \]
 \end{corollary}
@@ -397,10 +403,11 @@ The following is another corollary of the proof of
 \lemmaref{lem:partitsizebound}, which we will use to compute an upper bound to
 the Rademacher average on $\Sam$.
 
+
 \begin{corollary}\label{corol:cifreq}
   Let $B$ be an itemset in $\partit_{A,\tau}$. Then
   \[
-    \freq_\Sam(B) \le \min \left\{ \frac{\lceil\lambda n\rceil -2}{n}, \frac{1 +
+    \freq_\Sam(B) \le \min \left\{ \frac{\lceil\lambda n\rceil -1}{n}, \frac{1 +
     h_{A,k_{A,\tau}}-\ell_{A,\tau}}{n} \right\} \enspace.
   \]
 \end{corollary}
@@ -559,10 +566,12 @@ can be obtained with a single scan of the sample (see \sectionref{sec:fixed}).
       \left[ \cosh (s) \right]^{\freq_\Sam(A) n} \nonumber \\
       & + \left.
     \displaystyle\sum_{r=1}^{\chi_A}\sum_{j=1}^{g_{A,r}}
-    \min\left\{2^{\min\{r, h_{A,r} - j\}}, \displaystyle\sum_{i=0}^{\lceil\lambda
+    \min\left\{2^r
+      %{\min\{r, h_{A,r} - j\}}
+      , \displaystyle\sum_{i=0}^{\lceil\lambda
       n\rceil-2} \binom{h_{A,r} - j}{i} \right\}
       \left[ \cosh (s) \right]^{\min \left\{ \lceil
-      n\lambda\rceil - 2, 1 + h_{A,r} - j \right\}}
+      n\lambda\rceil - 1, 1 + h_{A,r} - j \right\}}
     \right) \enspace.
   \end{align*}
   Then
@@ -629,13 +638,14 @@ can be obtained with a single scan of the sample (see \sectionref{sec:fixed}).
     \le& \sum_{\shortstack{\footnotesize$\tau\in
       \mathcal{P}_A$\\\footnotesize
   s.t.~$k_{A,\tau}>0$}}
-    \min\left\{2^{\min\{k_{A,\tau}, h_{A,k_{A,\tau}} -
-    \ell_{A,\tau}\}}, \sum_{i=0}^{\lceil\lambda
+    \min\left\{2^{k_{A,\tau}}
+        %\min\{k_{A,\tau}, h_{A,k_{A,\tau}} - \ell_{A,\tau}\}}
+        , \sum_{i=0}^{\lceil\lambda
       n\rceil-2} \binom{h_{A,k_{A,\tau}} - \ell_{A,\tau}}{i} \right\}
     %2^{\min\{k_{A,\tau},h_{A,k_{A,\tau}}-\ell_{A,\tau}\}}
     %e^{\frac{s^2}{2n^2}(1+h_{A,k_{A,\tau}}-\ell_{A,\tau})}
     \left[ \cosh (s) \right]^{\min \left\{ \lceil
-        n\lambda\rceil - 2, 1 + h_{A,k_{A,\tau}} -
+        n\lambda\rceil - 1, 1 + h_{A,k_{A,\tau}} -
     \ell_{A,\tau} \right\}}
     %e^{\frac{s^2}{2n^2}\min \left\{ \lceil n\lambda\rceil - 2, 1 + h_{A,k_{A,\tau}} -
     %\ell_{A,\tau} \right\}}
@@ -651,10 +661,11 @@ can be obtained with a single scan of the sample (see \sectionref{sec:fixed}).
   \equationref{eq:functionwboundsecond} as
   \begin{equation}\label{eq:functionwboundthird}
     \sum_{r=1}^{\chi_A}\sum_{j=1}^{g_{A,r}}
-    \min\left\{2^{\min\{r, h_{A,r} - j\}}, \sum_{i=0}^{\lceil\lambda
-      n\rceil-2} \binom{h_{A,r} - j}{i} \right\}
+    \min\left\{2^{r}
+        %\min\{r, h_{A,r} - j\}}
+      , \sum_{i=0}^{\lceil\lambda n\rceil-2} \binom{h_{A,r} - j}{i} \right\}
       \left[ \cosh (s) \right]^{\min \left\{ \lceil
-          n\lambda\rceil - 2, 1 + h_{A,r} - j \right\}}
+          n\lambda\rceil - 1, 1 + h_{A,r} - j \right\}}
     %e^{\frac{s^2}{2n^2}\min \left\{ \lceil n\lambda\rceil - 2, 1 + h_{A,r} -
     %j \right\}}
     \enspace.
